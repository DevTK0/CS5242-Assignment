{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due week 8, 10 October 2023, 1800hours\n",
    "# Question 1 - Optimization (2.5 Marks)\n",
    "\n",
    "![Figure 1](./figures/Figure_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Figure 1` shows the plot of a 1D loss function. Apply gradient descend to optimize the loss function starting from point $O$. There is a bump at a distance $L = 1$ away with the bump dimension $h Ã— 2h$.\n",
    "\n",
    "## Question 1.1\n",
    "\n",
    "Explain what happens when you apply the standard gradient descent algorithm. Let the learning rate of the gradient descend be $\\eta = 0.3$. Given $h = 0.5$.\n",
    "\n",
    "$$ x  \\leftarrowtail x - \\eta \\frac{\\partial L}{\\partial x} \\tag{1} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the current epoch be $t$,  \n",
    "We start off with $t = 0$, $x_0 = 0$.  \n",
    "From x = 0 to 1, the gradient is $\\frac{\\partial L}{\\partial x} =  \\frac{(1-0)}{(0-1)} = -1$  \n",
    "\n",
    "When $t = 1$, $x_1 = 0 - (0.3)(-1) = 0.3$  \n",
    "When $t = 2$, $x_2 = x_1 - (0.3)(-1) = 0.6$  \n",
    "When $t = 3$, $x_3 = x_2 - (0.3)(-1) = 0.9$  \n",
    "When $t = 4$, $x_4 = x_3 - (0.3)(-1) = 1.2$  \n",
    "\n",
    "From x = 1 to 1.5, the gradient is $\\frac{\\partial L}{\\partial x} = \\frac{0.5 - 0}{1.5-1} = 1$  \n",
    "When $t = 5$, $x_5 = x_4 - (0.3)(1) = 0.9$   \n",
    "\n",
    "The steps in the fourth and fifth epoch will keep on repeating and x will be stuck in the local minima.\n",
    "\n",
    "The code below is used to verify the expected behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.5\n",
    "L = 1\n",
    "\n",
    "def get_gradient(x):\n",
    "\n",
    "    if x < 1:\n",
    "        return -1.0\n",
    "    elif 1 < x < (L + h):\n",
    "        return (h - 0) / (L + h - L)\n",
    "    elif x == L + h or x == L:\n",
    "        return 0.0\n",
    "    elif (L + h) < x <= (L + 2 * h):\n",
    "        return (0 - h) / (L + 2 * h - (L + h))\n",
    "    else:\n",
    "        return -0.01\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, eta, gradient):\n",
    "    return x - (eta * gradient)\n",
    "\n",
    "# start at (0,1)\n",
    "x = 0\n",
    "lr = 0.3\n",
    "\n",
    "for i in range(10):\n",
    "    g = get_gradient(x)\n",
    "    x = gradient_descent(x, lr, g)\n",
    "    print(\"Epoch: {}, x: {}, gradient: {}\".format(i + 1, x, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2\n",
    "![Figure 2](./figures/Figure_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of gradient descend, apply adam optimisation with parameters given in `figure 2`. What is the max height '$h$' of the bump in which the adam optimiser will escape the local min at '$x$'? Use $\\alpha = 0.3$ and $\\epsilon = 0$ in your calculations. Round '$h$' to 2 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2\n",
    "\n",
    "h = 0.41\n",
    "\n",
    "$\\beta_1 = 0.9, \\beta_2 = 0.999$  \n",
    "In the first epoch,   \n",
    "$m_0 = 0.9 * 0 + (1 - (0.9)) * (-1) = -0.1$  \n",
    "$v_0 = (0.999) * 0 + (1 - (0.999) * (-1)^2 = 0.001$  \n",
    "$\\hat{m} = m_0 / (1 - (0.9)^1) = -1$  \n",
    "$\\hat{v} = v_0 / (1 - (0.999)^1) = 1$  \n",
    "$\\theta_0 = 0 - 0.3 * \\hat{m} / \\sqrt{\\hat{v}} + 0 = 0.3$\n",
    "\n",
    "In the second epoch,  \n",
    "$m_1 = 0.9 * m_0 + (1 - (0.9)) * (-1) = -0.19$  \n",
    "$v_1 = (0.999) * v_0 + (1 - (0.999) * (-1)^2 = 0.00199$  \n",
    "$\\hat{m} = m_1 / (1 - (0.9)^2) = -1$  \n",
    "$\\hat{v} = v_1 / (1 - (0.999)^2) = 1$  \n",
    "$\\theta_0 = 0.3 - 0.3 * \\hat{m} / \\sqrt{\\hat{v}} + 0 = 0.6$\n",
    "\n",
    "...\n",
    "\n",
    "Epoch: 0, theta: 0.30000, gradient: -1.0, m: -0.10000, v: 0.00100, m_hat: -1.00000, v_hat: 1.00000  \n",
    "Epoch: 1, theta: 0.60000, gradient: -1.0, m: -0.19000, v: 0.00200, m_hat: -1.00000, v_hat: 1.00000  \n",
    "Epoch: 2, theta: 0.90000, gradient: -1.0, m: -0.27100, v: 0.00300, m_hat: -1.00000, v_hat: 1.00000  \n",
    "Epoch: 3, theta: 1.20000, gradient: -1.0, m: -0.34390, v: 0.00399, m_hat: -1.00000, v_hat: 1.00000  \n",
    "Epoch: 4, theta: 1.35348, gradient: 1.0, m: -0.20951, v: 0.00499, m_hat: -0.51161, v_hat: 1.00000  \n",
    "Epoch: 5, theta: 1.41018, gradient: 1.0, m: -0.08856, v: 0.00599, m_hat: -0.18900, v_hat: 1.00000  \n",
    "Epoch: 6, theta: 1.39851, gradient: 1.0, m: 0.02030, v: 0.00698, m_hat: 0.03891, v_hat: 1.00000  \n",
    "\n",
    "After epoch 5, adam will not have sufficient momentum to escape the local minima. Thus, h = 0.41 (to 2 d.p.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Adam parameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "alpha = 0.3\n",
    "epsilon = 0\n",
    "\n",
    "''' \n",
    "Adam function \n",
    "'''\n",
    "def adam(x=0):\n",
    "    m = 0\n",
    "    v = 0\n",
    "\n",
    "    for i in range(30):\n",
    "        x, m, v = step(x, m, v, i)\n",
    "    \n",
    "    \n",
    "    return x\n",
    "\n",
    "t = []\n",
    "g_t = []\n",
    "m_t = []\n",
    "v_t = []\n",
    "m_hat_t = []\n",
    "v_hat_t = []\n",
    "x_t = []\n",
    "\n",
    "def reset():\n",
    "    global t, g_t, m_t, v_t, m_hat_t, v_hat_t, x_t\n",
    "    t = []\n",
    "    g_t = []\n",
    "    m_t = []\n",
    "    v_t = []\n",
    "    m_hat_t = []\n",
    "    v_hat_t = []\n",
    "    x_t = []\n",
    "\n",
    "def log(i, x, g, m, v, m_hat, v_hat):\n",
    "    t.append(i)\n",
    "    g_t.append(g)\n",
    "    m_t.append(m)\n",
    "    v_t.append(v)\n",
    "    m_hat_t.append(m_hat)\n",
    "    v_hat_t.append(v_hat)\n",
    "    x_t.append(x)\n",
    "\n",
    "''' \n",
    "A single iteration of the Adam algorithm.\n",
    "'''\n",
    "def step(x, m, v, i):\n",
    "    g = get_gradient(x)\n",
    "    m = beta1 * m + (1 - beta1) * g\n",
    "    v = beta2 * v + (1 - beta2) * (g ** 2)\n",
    "    m_hat = m / (1 - beta1 ** (i + 1))\n",
    "    v_hat = v / (1 - beta2 ** (i + 1))\n",
    "    x = x - alpha * m_hat / (math.sqrt(v_hat) + epsilon)\n",
    "    print(\"Epoch: {}, theta: {:.5f}, gradient: {}, m: {:.5f}, v: {:.5f}, m_hat: {:.5f}, v_hat: {:.5f}\".format(i, x, g, m, v, m_hat, v_hat))\n",
    "    log(i, x, g, m, v, m_hat, v_hat)\n",
    "\n",
    "    return x, m, v\n",
    "\n",
    "'''\n",
    "Iterate through different values of h to find the smallest value of h that can escape the local minima.\n",
    "'''\n",
    "# def find_h():\n",
    "#     global h\n",
    "#     h = 5.0\n",
    "#     for i in range(10000):\n",
    "\n",
    "#         x = adam()\n",
    "\n",
    "#         if x > (1 + h):\n",
    "#             # escape local minima\n",
    "#             print(\"h: {:.3f}, x: {}\".format(h, x))\n",
    "#             break\n",
    "\n",
    "#         h -= 0.001\n",
    "\n",
    "#     return h\n",
    "\n",
    "# find_h()\n",
    "adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3\n",
    "Plot the following values with respect to $t$ in a single plot and explain your observations. Use learning rate $= 0.3$\n",
    "$$ g_t, m_t, v_t, \\hat{m_t}, \\hat{v_t}, x \\tag{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h = 5.0\n",
    "reset()\n",
    "adam()\n",
    "\n",
    "plt.plot(t, x_t, label=\"x\")\n",
    "plt.plot(t, g_t, label=\"gradient\")\n",
    "plt.plot(t, m_t, label=\"m\")\n",
    "plt.plot(t, v_t, label=\"v\")\n",
    "plt.plot(t, m_hat_t, label=\"m_hat\")\n",
    "plt.plot(t, v_hat_t, label=\"v_hat\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adam gradient descent gets stuck in the local minima (i.e. $x$ can't exceed ~1.4). As it continues to remain stuck, it gradually loses its momentum as can be seen by the lower and lower peaks in $m$ and $\\hat{m}$ values as $t$ increases.\n",
    "\n",
    "v and $\\hat{v}$ are used for z-scoring, but in this case, the variance is too small and doesn't really contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.4\n",
    "Perform the Adam optimizer starting at $x = 2$ for the following function and plot $g_t, m_t, v_t,  \\hat{m_t}, \\hat{v_t}, x$ w.r.t $t$. Explain your observations. Use learning rate = 0.3 for 30 iterations.\n",
    "\n",
    "$$ReLU(x), Sigmoid(x), |x| \\tag{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ReLU\n",
    "def get_gradient(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    elif x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "reset()\n",
    "adam(2)\n",
    "\n",
    "plt.plot(t, x_t, label=\"x\")\n",
    "plt.plot(t, g_t, label=\"gradient\")\n",
    "plt.plot(t, m_t, label=\"m\")\n",
    "plt.plot(t, v_t, label=\"v\")\n",
    "plt.plot(t, m_hat_t, label=\"m_hat\")\n",
    "plt.plot(t, v_hat_t, label=\"v_hat\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ReLU(x), at x = 2, the gradient is 1. Thus, for the gradient descent, the adam algorithm starts to \"move backwards\". Since ReLU has a zero gradient when x < 0, the adam algorithm will trickle backwards until it loses its momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def get_gradient(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))    \n",
    "\n",
    "h = 100\n",
    "reset()\n",
    "adam(2)\n",
    "\n",
    "plt.plot(t, x_t, label=\"x\")\n",
    "plt.plot(t, g_t, label=\"gradient\")\n",
    "plt.plot(t, m_t, label=\"m\")\n",
    "plt.plot(t, v_t, label=\"v\")\n",
    "plt.plot(t, m_hat_t, label=\"m_hat\")\n",
    "plt.plot(t, v_hat_t, label=\"v_hat\")\n",
    "plt.legend()\n",
    "plt.ylim([-1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar behavior to ReLU except with different, smoother gradients. The adam algorithm will continue gradient descent moving backwards and stagnate as it loses momentum.\n",
    "\n",
    "Since sigmoid doesn't have a sharp dropoff to 0 gradient unlike ReLU, the gradient descent is able to progress much further (i.e. more negative) than ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Absolute value\n",
    "def get_gradient(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    elif x < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "h = 100\n",
    "reset()\n",
    "adam(2)\n",
    "\n",
    "plt.plot(t, x_t, label=\"x\")\n",
    "plt.plot(t, g_t, label=\"gradient\")\n",
    "plt.plot(t, m_t, label=\"m\")\n",
    "plt.plot(t, v_t, label=\"v\")\n",
    "plt.plot(t, m_hat_t, label=\"m_hat\")\n",
    "plt.plot(t, v_hat_t, label=\"v_hat\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm alternates between the positive and negative gradients of the |x| function, losing momentum with each cycle and is expected to eventually converge at x = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Autoencoder (2.5 Marks)\n",
    "\n",
    "## Question 2.1\n",
    "Make an autoencoder for the MNIST data set using the following architecture.\n",
    " \n",
    "1. Input $28Ã—28Ã—1$.\n",
    "2. Flatten $784$\n",
    "3. Fully connected $784 â†’ 196$ with ReLU.\n",
    "4. Fully connected $196 â†’ 49$ with ReLU. \n",
    "5. Fully connected $49 â†’ \\lambda$ with ReLU.\n",
    "6. Fully connected $\\lambda â†’ 49$ with ReLU.\n",
    "7. Fully connected $49 â†’ 196$ with ReLU. \n",
    "8. Fully connected $196 â†’ 784$ with ReLU. \n",
    "9. Reshape to $28Ã—28Ã—1$.\n",
    "\n",
    "Keeping all the parameters the same (example: epochs, batch size, learning rate etc,.), train the autoencoder on the the whole of MNIST training dataset (60k images) using this architecture for $\\lambda = 2$ and $\\lambda = 32$. Use L1 loss function and adam optimizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=64)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# train_features, train_labels = next(iter(train_loader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# img = train_features[0].squeeze()\n",
    "# label = train_labels[0]\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(f\"Label: {label}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, l):\n",
    "        super().__init__()\n",
    "        self.identity = nn.Identity()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 196),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(196, 49),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(49, l),\n",
    "            nn.ReLU()       \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(l, 49),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(49, 196),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(196, 28 * 28),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.unflatten = nn.Unflatten(1, (1, 28, 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.unflatten(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def autograd(model, criterion, optimizer):\n",
    "    \n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    accs_train = []\n",
    "    accs_test = []\n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        train_loss = 0.\n",
    "        total = 0\n",
    "        correct = 0\n",
    "    \n",
    "        for (inputs, _) in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predicted = model(inputs)\n",
    "            loss = criterion(predicted, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            # losses_train.append(loss.item())\n",
    "        with torch.no_grad():\n",
    "\n",
    "            train_loss = train_loss / len(train_loader)\n",
    "\n",
    "            # logs\n",
    "            losses_train.append(train_loss)\n",
    "\n",
    "            if num_epochs <= 10:\n",
    "              print(\"Epoch: {}/{}, time: {:.1f}s | train loss: {:.5f}\".format(epoch + 1, num_epochs, time.time() - start, train_loss)) \n",
    "            elif epoch % 10 == 0:\n",
    "              print(\"Epoch: {}/{} | train loss: {:.5f}\".format(epoch, num_epochs, train_loss))\n",
    "\n",
    "    return {\"loss\": losses_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = AutoEncoder(2)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.01)\n",
    "\n",
    "history = autograd(model_2, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"loss: \", history[\"loss\"][-1])\n",
    "    plt.plot(history[\"loss\"], label=\"train loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_32 = AutoEncoder(32)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model_32.parameters(), lr=0.01)\n",
    "\n",
    "history = autograd(model_32, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"loss: \", history[\"loss\"][-1])\n",
    "    plt.plot(history[\"loss\"], label=\"train loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_features, test_labels = next(iter(test_loader))\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    img = test_features[i].squeeze()\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    result = model_2(test_features)\n",
    "    img2 = result[i].squeeze()\n",
    "    plt.imshow(img2, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    result = model_32(test_features)\n",
    "    img2 = result[i].squeeze()\n",
    "    plt.imshow(img2, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explain what you notice about the results from these two scenarios? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller the latent space, the more \"lossy\" the autoencoder. This can be seen by the blurer features, less pixels, more noise etc. The loss value is also higher and the model tends to stagnate earlier as compared to $\\lambda = 32$ where the model is able to make more improvements with more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For both the scenarios, submit the training loss vs epochs, sample input image and the reconstructed output image. (1 image with 6 subimages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss_2](./outputs/loss_2_q2.png)\n",
    "![Input](./outputs/input_q2.png)\n",
    "![lambda_2_output](./outputs/output_2_q2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss_32](./outputs/loss_32_q2.png)\n",
    "![Input](./outputs/input_q2.png)\n",
    "![lambda_32_output](./outputs/output_32_q2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "\n",
    "![Figure 3](./figures/Figure_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of fully connected layers, design the autoencoder with convolutional layers following the [figure 3](#question-22). Similar to [question 2.1](#question-21), use activation function ReLu, L1 loss function and adam optimizer and train the autoencoder on the MNIST training dataset for $\\lambda = 2$ and $\\lambda = 32$.\n",
    "- Explain what you notice about the results from these two scenarios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, l):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 8, 3, padding=2, dilation=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(8, 8, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(392, l),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(l, 392),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (8, 7, 7)),\n",
    "            nn.ConvTranspose2d(8, 8, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(8, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(16, 1, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1, 1, 3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = CNN(2)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "autograd(model_2, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"loss: \", history[\"loss\"][-1])\n",
    "    plt.plot(history[\"loss\"], label=\"train loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_32 = CNN(32)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model_32.parameters(), lr=0.001)\n",
    "\n",
    "history = autograd(model_32, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"loss: \", history[\"loss\"][-1])\n",
    "    plt.plot(history[\"loss\"], label=\"train loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_features, test_labels = next(iter(test_loader))\n",
    "    idx = 4\n",
    "    img = test_features[idx].squeeze()\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    result = model_2(test_features)\n",
    "    img = result[idx].squeeze()\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    result = model_32(test_features)\n",
    "    img2 = result[idx].squeeze()\n",
    "    plt.imshow(img2, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explain what you notice about the results from these two scenarios?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results tends to be better in the CNN autoencoders than the typical autoencoders.  \n",
    "\n",
    "Similar to the non-CNN autoencoder, when $\\lambda = 2$, the latent space is a lot smaller and the amount of information passed onto the decoder is also a lot lesser. This results in outputs that feel more \"compressed\" and retaining less features. We can see it in the outputs whereby $\\lambda = 2$ tends to be blurer and have less features as compared to $\\lambda = 32$.\n",
    "\n",
    "One difference between CNN autoencoders and the non-CNN autoencoder is that the images seem to be \"smoother\" (e.g. non-cnn has very sharp holes compared to cnn where pixels have like an anti-aliasing effect). This makes sense as the CNN uses the kernel to take into account surrounding pixels rather than individual pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss_cnn_2](./outputs/loss_2_q2.2.png)\n",
    "![Input](./outputs/input_q2.2.png)\n",
    "![lambda_2_output](./outputs/output_2_q2.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss_cnn_32](./outputs/loss_32_q2.2.png)\n",
    "![Input](./outputs/input_q2.2.png)\n",
    "![lambda_32_output](./outputs/output_32_q2.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Common features - (2.5 Marks)\n",
    "If an autoencoder is used to reconstruct MNIST images, we say that the latent variables contain the instance specific information and the weights and bias contain common features among instances in the data set. Then, how can we extract common features from a dataset?\n",
    "  \n",
    "Take the model trained in question 2.2 (both $\\lambda = 2$ and $\\lambda = 32$. Pass the whole MNIST training data set through the trained model. Record all the latent features $z_1, z_2, ... , z_{60000}$ and then take its\n",
    "mean value.\n",
    "\n",
    "$$ \\mu = \\frac{1}{60,000} \\sum_1^{60,000} z_i \\tag{4}$$\n",
    "\n",
    "This mean value Î¼ must contain common features (together with all weights and bias) of the data set and is the same value for all instances. Feed Î¼ into the decoder and observe its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "latent_features_2 = []\n",
    "latent_features_32 = []\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, _ = data\n",
    "        output_2 = model_2.encoder(inputs)\n",
    "        output_32 = model_32.encoder(inputs)\n",
    "\n",
    "        latent_features_2.append(output_2)\n",
    "        latent_features_32.append(output_32)\n",
    "        \n",
    "latent_features_2 = torch.cat(latent_features_2, dim=0)\n",
    "latent_features_32 = torch.cat(latent_features_32, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_latent_features_2 = torch.mean(latent_features_2, dim=0)\n",
    "print(mean_latent_features_2)\n",
    "mean_latent_features_32 = torch.mean(latent_features_32, dim=0)\n",
    "print(mean_latent_features_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_2 = model_2.decoder(mean_latent_features_2.unsqueeze(dim=0))\n",
    "output_32 = model_32.decoder(mean_latent_features_32.unsqueeze(dim=0))\n",
    "\n",
    "print(output_2)\n",
    "print(output_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    img2 = output_2.squeeze()\n",
    "    plt.imshow(img2, cmap=\"gray\")\n",
    "    plt.title(\"Î»=2\")\n",
    "    plt.show()\n",
    "\n",
    "    img32 = output_32.squeeze()\n",
    "    plt.imshow(img32, cmap=\"gray\")\n",
    "    plt.title(\"Î»=32\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explain what you notice about the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both have similar shapes, but $\\lambda = 32$ has a bit more features than $\\lambda = 2$. This makes sense since we are taking the mean of the latent spaces and $\\lambda=2$ is a smaller latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For both ($\\lambda = 2$ and $\\lambda = 32$), submit the reconstructed output image. (1 image with 2 subimages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lambda_2](./outputs/q3_2.png)\n",
    "![lambda_32](./outputs/q3_32.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Understanding pytorch - (2.5 Marks)\n",
    "Given: $32 Ã— 1$ pixel input (*pixel_input.pt*) and $3 Ã— 1$ filters (*filter.pt*). Tip: Use `torch.load` and `torch.save`.\n",
    "\n",
    "Implement the following using pytorch to generate `torch_xxx_out` tensors. Re-implement again, this time without using any deep learning library to generate `my_xxx_out` tensors. Compare the output tensors and ensure that they match.\n",
    "\n",
    "1. `torch.nn.MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, return_indices=False, ceil_mode=False)`\n",
    "2. `torch.nn.AvgPool1d(kernel_size=2, stride=1, padding=0, ceil_mode=False, count_include_pad=True)`\n",
    "3. `torch.nn.functional.conv1d(input, filter, bias = None, stride = 1, padding = 0, dilation = 1, groups = 1)`\n",
    "4. `torch.nn.Sigmoid()`\n",
    "5. `torch.nn.BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)`\n",
    "6. `torch.nn.Linear(in_features, out_features, bias=True)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch load file\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pixel_input = torch.load('./data/pixel_input.pt').double()\n",
    "filter_4_3 = torch.load('./data/4_3_filter.pt').double()\n",
    "\n",
    "print(pixel_input)\n",
    "print(filter_4_3)\n",
    "\n",
    "torch_001_output = nn.MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, return_indices=False, ceil_mode=False)(pixel_input)\n",
    "torch_002_output = nn.AvgPool1d(kernel_size=2, stride=1, padding=0, ceil_mode=False, count_include_pad=True)(torch_001_output)\n",
    "torch_003_output = F.conv1d(torch_002_output, filter_4_3, bias=None, stride=1, padding=0, dilation=1, groups=1)\n",
    "torch_004_output = nn.Sigmoid()(torch_003_output)\n",
    "torch_005_output = nn.BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True, device=None, dtype=torch.float64)(torch_004_output)\n",
    "\n",
    "linear = nn.Linear(in_features=28, out_features=1, bias=True, dtype=torch.float64)\n",
    "torch_006_output = linear(torch_005_output)\n",
    "weights, bias = linear.state_dict()['weight'], linear.state_dict()['bias']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPool1d(pixel_input):\n",
    "    kernel_size = 2\n",
    "    stride = 1\n",
    "    padding = 0\n",
    "\n",
    "    output_shape = (pixel_input.shape[0], pixel_input.shape[1], (pixel_input.shape[2] - kernel_size + 2 * padding) // stride + 1)\n",
    "    output = torch.zeros(output_shape)\n",
    "\n",
    "    for i in range(output_shape[2]):\n",
    "        start = i \n",
    "        end = start + kernel_size\n",
    "        \n",
    "        output[:,:,i] = torch.max(pixel_input[:, :, start:end]).item()\n",
    "\n",
    "    return output\n",
    "\n",
    "MaxPool1d(pixel_input) == torch_001_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AvgPool1d(pixel_input):\n",
    "    kernel_size = 2\n",
    "    stride = 1\n",
    "    padding = 0\n",
    "\n",
    "    output_shape = (pixel_input.shape[0], pixel_input.shape[1], (pixel_input.shape[2] - kernel_size + 2 * padding) // stride + 1)\n",
    "    output = torch.zeros(output_shape)\n",
    "\n",
    "    for i in range(output_shape[2]):\n",
    "        start = i \n",
    "        end = start + kernel_size\n",
    "       \n",
    "        output[:,:,i] = torch.mean(pixel_input[:, :, start:end]).item()\n",
    "\n",
    "    return output\n",
    "\n",
    "AvgPool1d(torch_001_output) == torch_002_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(pixel_input, filter):\n",
    "    kernel_size=filter.shape[2]\n",
    "    stride=1 \n",
    "    padding=0 \n",
    "   \n",
    "    output_shape = (pixel_input.shape[0], pixel_input.shape[1], (pixel_input.shape[2] - kernel_size + 2 * padding) // stride + 1)\n",
    "    output = torch.zeros(output_shape).double()\n",
    "\n",
    "    for i in range(output_shape[2]):\n",
    "        start = i \n",
    "        end = start + kernel_size\n",
    "        \n",
    "        output[:,:,i] = torch.matmul(pixel_input[:, :, start:end], torch.transpose(filter_4_3, 1, 2)).item()\n",
    "\n",
    "    return output\n",
    "\n",
    "conv1d(torch_002_output, filter_4_3) == torch_003_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(pixel_input):\n",
    "    return (1 / (1 + torch.exp(-pixel_input)))\n",
    "\n",
    "sigmoid(torch_003_output) == torch_004_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchNorm1d(pixel_input):\n",
    "    running_mean = 0.\n",
    "    running_var = 1. \n",
    "    eps=1e-05\n",
    "    momentum=0.1\n",
    "\n",
    "    var = torch.var(pixel_input, unbiased=False)\n",
    "    mean = torch.mean(pixel_input)\n",
    "\n",
    "    running_mean = (1 - momentum) * running_mean + momentum * torch.mean(pixel_input)\n",
    "    running_var = (1 - momentum) * running_var + momentum * torch.var(pixel_input, unbiased=True)\n",
    "\n",
    "    # print((pixel_input - running_mean) / math.sqrt(running_var + eps))\n",
    "    return (pixel_input - mean) / math.sqrt(var + eps)\n",
    "\n",
    "output = torch.round(BatchNorm1d(torch_004_output), decimals = 10)\n",
    "expected = torch.round(torch_005_output, decimals=10)\n",
    "print(output ==  expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\"\"\"\n",
    "nn.Linear automatically generates weights and bias using a normal distribution.\n",
    "Here we use the same weights and bias as nn.Linear for the sake of verifying our implementation.\n",
    "\"\"\"\n",
    "def Linear(pixel_input, weights, bias):\n",
    "    in_features=28\n",
    "    out_features=1\n",
    "\n",
    "    output = torch.matmul(pixel_input, torch.transpose(weights, 0, 1)) + bias\n",
    "\n",
    "    return output\n",
    "\n",
    "Linear(torch_005_output, weights, bias) == torch_006_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: CIFAR10 - (2.5 Marks)\n",
    "## Question 5.1\n",
    "Make a neural network with a few layers of convolution and fully connected layers. Construct your network from scratch. Do not download code and use, e.g. do not use pytorch to call Resnet. You may use low level pytorch function such as `nn.Linear` and `nn.Conv2d`. Train your network on the full CIFAR training dataset to achieve testing accuracy of > 90% on the CIFAR testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as t\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transforms = t.Compose([\n",
    "    t.RandomRotation(15),\n",
    "    t.RandomHorizontalFlip(0.5),\n",
    "    t.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    t.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=t.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(training_data, shuffle=True, batch_size=128)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.norm4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.norm5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.norm6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 512)\n",
    "        self.norm7 = nn.BatchNorm1d(512)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm1(F.relu(self.conv1(x)))\n",
    "        x = self.norm2(F.relu(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        # x = self.dropout1(x)\n",
    "\n",
    "        x = self.norm3(F.relu(self.conv3(x)))\n",
    "        x = self.norm4(F.relu(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        # x = self.dropout2(x)\n",
    "\n",
    "        x = self.norm5(F.relu(self.conv5(x)))\n",
    "        x = self.norm6(F.relu(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "        # x = self.dropout3(x)\n",
    "\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.norm7(F.relu(self.fc1(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion):\n",
    "    \n",
    "        losses = 0.\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for (inputs, expected) in test_loader:\n",
    "            # inputs, expected = inputs.to(device), expected.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, expected)\n",
    "            losses += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += expected.size(0)\n",
    "            correct += (predicted == expected).sum().item()\n",
    "\n",
    "        valid_loss = losses / len(test_loader)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def autograd(model, criterion, optimizer, num_epochs=10):\n",
    "    \n",
    "    logs = {\"loss\": [], \"val_loss\": [], \"accuracy\": [], \"val_accuracy\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        train_loss = 0.\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        for (inputs, expected) in train_loader:\n",
    "            # inputs, expected = inputs.to(device), expected.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predicted = model(inputs)\n",
    "            loss = criterion(predicted, expected)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            # batch specific logging\n",
    "            # losses_train.append(loss.item())\n",
    "\n",
    "            _, value = torch.max(predicted.data, 1)\n",
    "            total += expected.size(0)\n",
    "            correct += (value == expected).sum().item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            train_loss = train_loss / len(train_loader)            \n",
    "            train_acc = correct / total            \n",
    "\n",
    "            val_loss, val_acc = validation(model, criterion)\n",
    "\n",
    "            # logs\n",
    "            logs[\"loss\"].append(train_loss)\n",
    "            logs[\"val_loss\"].append(val_loss)\n",
    "            logs[\"accuracy\"].append(train_acc)\n",
    "            logs[\"val_accuracy\"].append(val_acc)\n",
    "\n",
    "            if num_epochs % 10 == 10:\n",
    "              print(f\"Epoch: {epoch}/{num_epochs}, runtime: {time.time() - start}s | Loss: {train_loss:.5f}, Accuracy: {train_acc:.2f}% | Test loss: {val_loss:.5f}, Test acc: {val_acc:.2f}%\")\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "# model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "history = autograd(model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"loss: \", history[\"loss\"][-1], \" test_loss: \", history[\"val_loss\"][-1])\n",
    "    print(\"accuracy: \", history[\"accuracy\"][-1], \" test_accuracy: \", history[\"val_accuracy\"][-1])\n",
    "    plt.plot(history[\"loss\"], label=\"train loss\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"test loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history[\"accuracy\"], label=\"train accuracy\")\n",
    "    plt.plot(history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Were you able to achive more than 90% testing accuracy? Why was it difficult? Explain briefly what you did to achieve 90% testing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No.\n",
    "\n",
    "Although it was possible to get really high training accuracy (>90%) with just a simple architecture, the test accuracy often lagged behind. This showed that I needed better regularisation techniques in order to allow my model to generalise better into the test dataset. The following techniques were used:\n",
    "- Data Augmentation\n",
    "- Dropout\n",
    "- Batch Normalisation\n",
    "\n",
    "With these regularisation techniques, test and training accuracy started to be a lot closer. However, it was still difficult to obtain above 90% as later runs only resulted in marginal gains.\n",
    "\n",
    "This particular architecture seemed to still to be able to improve further. However, training was starting to get too expensive (>150 epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Submit the \n",
    "  1. Training loss vs Epochs\n",
    "  2. Training accuracy vs Epochs \n",
    "  3. Testing loss vs Epochs \n",
    "  4. Testing acuracy vs Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./outputs/loss_q5.png)\n",
    "![](./outputs/accuracy_q5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5.2\n",
    "Now train only on a subset of the CIFAR10 training dataset. Use the below subset conditions. Keep the full CIFAR10 testing set intact. Repeat the above experiment and tune the hyper-parameters as best as you can.\n",
    "\n",
    "1. 1 instance per class, a total of 10 train images only.\n",
    "2. 10 instances per class\n",
    "3. 100 instances per class\n",
    "4. 1000 instances per class\n",
    "5. full train data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot the (Training accuracy - testing accuracy) vs number of training data used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "loaders = []\n",
    "num_instances = 1000\n",
    "\n",
    "class_indices = {}\n",
    "for i in range(len(training_data)):\n",
    "    label = training_data[i][1]\n",
    "    if label not in class_indices:\n",
    "        class_indices[label] = []\n",
    "    class_indices[label].append(i)\n",
    "\n",
    "selected_indices = []\n",
    "\n",
    "for i in range(len(class_indices.keys())):\n",
    "    for j in range(num_instances):\n",
    "        selected_indices.append(class_indices[i][j])\n",
    "\n",
    "subset = torch.utils.data.Subset(training_data, selected_indices)\n",
    "train_loader = torch.utils.data.DataLoader(subset, batch_size=len(subset), shuffle=True)\n",
    "\n",
    "# train_features, train_labels = next(iter(train_loader))\n",
    "# print(train_features.shape)\n",
    "# print(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "autograd(model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # images, labels = images.to(device), labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./outputs/accuracy_q5.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: Receptive field - (2.5 Marks)\n",
    "The receptive field is defined as the region in the input space that a particular CNNâ€™s feature is looking at (i.e. be affected by). Compute size of receptive fields with respect to the input image across the layers. Fill in the empty cells in the table 1\n",
    "\n",
    "Table 1: Fill in receptive field size of a single pixel at the output with respect to the input image.\n",
    "\n",
    "|                |                                            |\n",
    "| -------------- | ------------------------------------------ |\n",
    "| conv2d(k,s)    | conv2d with kernel k x k and stride s x s  |\n",
    "| maxpool2d(k,s) | maxpool with kernel k x k and stride s x s |\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| S.No | layer1       | layer2         | layer3         | layer4         | layer 5        | receptive field |\n",
    "| ---- | ------------ | -------------- | -------------- | -------------- | -------------- | --------------- |\n",
    "| 1    | conv2d(3,1)  | conv2d(3,1)    | conv2d(1,1)    | maxpool2d(2,2) | conv2d(2,2)    | 8x8             |\n",
    "| 2    | conv2d(3,1)  | maxpool2d(2,2) | conv2d(2,2)    | maxpool2d(2,2) | conv2d(3,1)    | 26x26           |\n",
    "| 3    | conv2d(5,1)  | maxpool2d(3,1) | conv2d(4,1)    | maxpool2d(2,2) | conv2d(3,1)    | 15x15           |\n",
    "| 4    | conv2d(7,2)  | conv2d(5,1)    | conv2d(3,2)    | conv2d(3,1)    | conv2d(1,1)    | 27x27           |\n",
    "| 5    | conv2d(4,1)  | conv2d(3,2)    | maxpool2d(2,2) | conv2d(3,1)    | maxpool2d(2,2) | 20x20           |\n",
    "| 6    | conv2d(7,2)  | conv2d(5,2)    | maxpool2d(2,2) | conv2d(5,2)    | conv2d(7,2)    | 147x147         |\n",
    "| 7    | conv2d(3,3)  | maxpool2d(2,2) | conv2d(5,3)    | maxpool2d(3,3) | conv2d(5,1)    | 282x282         |\n",
    "| 8    | conv2d(4,2)  | maxpool2d(2,2) | conv2d(3,1)    | conv2d(1,1)    | conv2d(2,1)    | 18x18           | \n",
    "| 9    | conv2d(4,2)  | maxpool2d(2,2) | conv2d(3,1)    | conv2d(1,1)    | conv2d(2,1)    | 18x18           |\n",
    "| 10   | conv2d(11,2) | conv2d(7,2)    | maxpool2d(2,2) | conv2d(5,2)    | conv2d(3,1)    | 91x91           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "k: kernel size\n",
    "s: stride\n",
    "l: current layer\n",
    "\n",
    "previous layer rf * stride\n",
    "\"\"\"\n",
    "def ReceptiveFieldSize(l, k, s):\n",
    "    if (l == 0):\n",
    "        return 1\n",
    "    return k[l] + (ReceptiveFieldSize(l-1, k, s) - 1) * s[l]\n",
    "\n",
    "k = [1, 2, 2, 1, 3, 3]\n",
    "s = [1, 2, 2, 1, 1, 1]\n",
    "print(\"1: \", ReceptiveFieldSize(5, k, s))\n",
    "\n",
    "k = [1,3, 2, 2, 2, 3]\n",
    "s = [1,1,2,2,2,1]\n",
    "print(\"2: \", ReceptiveFieldSize(5, k, s))\n",
    "\n",
    "k = [1,3,2,4,3,5]\n",
    "s = [1,1,2,1,1,1]\n",
    "print(\"3: \", ReceptiveFieldSize(5, k, s))\n",
    "\n",
    "k = [1,1,3,3,5,7]\n",
    "s = [1,1,1,2,1,2]\n",
    "print(\"4: \", ReceptiveFieldSize(5, k, s))\n",
    "\n",
    "k = [1,2,3,2,3,4]\n",
    "s = [1,2,1,2,2,1]\n",
    "print(\"5: \", ReceptiveFieldSize(5, k, s))\n",
    "\n",
    "k = [1,7,5,2,5,7]\n",
    "s = [1,2,2,2,2,2]\n",
    "print(\"6: \", ReceptiveFieldSize(5, k, s))\n",
    "\n",
    "k = [1,5,3,5,2,3]\n",
    "s = [1,1,3,3,2,3]\n",
    "print(\"7: \", ReceptiveFieldSize(5, k, s))\n",
    "\n",
    "k = [1,2,1,3,2,4]\n",
    "s = [1,1,1,1,2,2]\n",
    "print(\"8: \", ReceptiveFieldSize(5, k, s))\n",
    "\n",
    "k = [1,2,1,3,2,4]\n",
    "s = [1,1,1,1,2,2]\n",
    "print(\"9: \", ReceptiveFieldSize(5, k, s))\n",
    "\n",
    "k = [1,3,5,2,7,11]\n",
    "s = [1,1,2,2,2,2]\n",
    "print(\"10: \", ReceptiveFieldSize(5, k, s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
