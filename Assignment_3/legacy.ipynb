{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "\tdef __init__(self, num_instances=2, num_samples_per_class=16, digit_arr=None, ucc_start=1, ucc_end=10):\n",
    "\t\t\n",
    "\t\tself._num_instances = num_instances\n",
    "\t\tself._num_samples_per_class = num_samples_per_class\n",
    "\t\tself._digit_arr = digit_arr\n",
    "\t\tself._ucc_start = ucc_start\n",
    "\t\tself._ucc_end = ucc_end\n",
    "\n",
    "\t\tself._num_digits = len(self._digit_arr)\n",
    "\n",
    "\t\tself._num_classes = self._ucc_end - self._ucc_start + 1\n",
    "\n",
    "\t\t# Load the dataset\n",
    "\t\tsplitted_dataset = np.load('../../data/mnist/splitted_mnist_dataset.npz')\n",
    "\n",
    "\t\tx_train = splitted_dataset['x_train']\n",
    "\t\ty_train = splitted_dataset['y_train']\n",
    "\t\tx_val = splitted_dataset['x_val']\n",
    "\t\ty_val = splitted_dataset['y_val']\n",
    "\t\t# x_test = splitted_dataset['x_test']\n",
    "\t\t# y_test = splitted_dataset['y_test']\n",
    "\n",
    "\t\tdel splitted_dataset\n",
    "\t\t\n",
    "\t\tx_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "\t\tx_train = x_train.astype('float32')\n",
    "\t\tx_train /= 255\n",
    "\t\t# this is just normalization\n",
    "\t\tx_train = (x_train-np.mean(x_train,axis=(1,2,3))[:,np.newaxis,np.newaxis,np.newaxis])/np.std(x_train,axis=(1,2,3))[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\t\tprint('x_train shape:', x_train.shape)\n",
    "\t\tprint(x_train.shape[0], 'train samples')\n",
    "\n",
    "\t\tself._x_train = x_train\n",
    "\t\tself._y_train = y_train\n",
    "\n",
    "\t\tdel x_train\n",
    "\t\tdel y_train\n",
    "\n",
    "\t\tx_val = x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], 1)\n",
    "\t\tx_val = x_val.astype('float32')\n",
    "\t\tx_val /= 255\n",
    "\t\tx_val = (x_val-np.mean(x_val,axis=(1,2,3))[:,np.newaxis,np.newaxis,np.newaxis])/np.std(x_val,axis=(1,2,3))[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\t\tprint(x_val.shape[0], 'val samples')\n",
    "\t\t\n",
    "\t\tself._x_val = x_val\n",
    "\t\tself._y_val = y_val\n",
    "\n",
    "\t\tdel x_val\n",
    "\t\tdel y_val\n",
    "\n",
    "\t\tself._digit_dict = self.get_digit_dict()\n",
    "\t\tself._class_dict_train = self.get_class_dict()\n",
    "\t\tself._class_dict_val = self.get_class_dict()\n",
    "\n",
    "\t\tself._labels = self.generate_labels()\n",
    "\n",
    "\t# digit dict is a dictionary with keys as digit0, digit1, ... and values as a dictionary with keys as value, train_indices, num_train, val_indices, num_val\n",
    "\tdef get_digit_dict(self):\n",
    "\t\tdigit_dict = dict()\n",
    "\t\n",
    "\t\tfor i in range(self._num_digits):\n",
    "\t\t\t\n",
    "\t\t\tdigit_key = 'digit' + str(i)\n",
    "\t\t\tdigit_value = self._digit_arr[i]\n",
    "\n",
    "\t\t\ttemp_digit_dict = dict()\n",
    "\n",
    "\t\t\ttemp_digit_dict['value'] = digit_value\n",
    "\t\t\ttemp_digit_dict['train_indices'] = np.where(self._y_train == digit_value)[0]\n",
    "\t\t\ttemp_digit_dict['num_train'] = len(temp_digit_dict['train_indices'])\n",
    "\t\t\ttemp_digit_dict['val_indices'] = np.where(self._y_val == digit_value)[0]\n",
    "\t\t\ttemp_digit_dict['num_val'] = len(temp_digit_dict['val_indices'])\n",
    "\n",
    "\t\t\tprint('{}:{}, num_train:{}, num_val:{}'.format(digit_key,digit_value,temp_digit_dict['num_train'],temp_digit_dict['num_val']))\n",
    "\n",
    "\t\t\tdigit_dict[digit_key] = temp_digit_dict\n",
    "\n",
    "\t\treturn digit_dict\n",
    "\n",
    "\n",
    "\t# this function returns a dictionary with keys as class_0, class_1, ... and values as a dictionary with keys as tuples_arr, num_tuples, index\n",
    "\t# it is used to generate the tuples of digits for each class which is then used to generate the bags for each class in the next_batch function\n",
    "\tdef get_class_dict(self):\n",
    "\t\telements_arr = np.arange(self._num_digits)\n",
    "\t\tclass_dict = dict()\n",
    "\t\tfor i in range(self._num_classes):\n",
    "\t\t\t\n",
    "\t\t\tclass_key = 'class_' + str(i)\n",
    "\n",
    "\t\t\ttemp_class_dict = dict()\n",
    "\t\t\t# print(elements_arr)\n",
    "\t\t\telements_list = list()\n",
    "\t\t\tfor j in combinations(elements_arr,i+self._ucc_start):\n",
    "\t\t\t\telements_list.append(np.array(j))\n",
    "\n",
    "\t\t\telements_array = np.array(elements_list)\n",
    "\t\t\tnp.random.shuffle(elements_array)\n",
    "\t\t\ttemp_class_dict['tuples_arr'] = elements_array\n",
    "\t\t\ttemp_class_dict['num_tuples'] = len(temp_class_dict['tuples_arr'])\n",
    "\t\t\ttemp_class_dict['index'] = 0\n",
    "\n",
    "\t\t\t# print(temp_class_dict['tuples_arr'].shape)\n",
    "\t\t\t# print('{}, num_tuples:{}'.format(class_key,temp_class_dict['num_tuples']))\n",
    "\n",
    "\t\t\tclass_dict[class_key] = temp_class_dict\n",
    "\n",
    "\t\treturn class_dict\n",
    "\n",
    "\tdef one_hot_label(self, label):\n",
    "\t\tone_hot_label = np.zeros(self._num_classes,dtype=np.int)\n",
    "\t\tone_hot_label[label]=1\n",
    "\t\treturn one_hot_label\n",
    "\n",
    "\tdef generate_labels(self):\n",
    "\t\tlabels_list = list()\n",
    "\t\tfor i in range(self._num_classes):\n",
    "\t\t\tlabels_list.append(self.one_hot_label(i))\n",
    "\n",
    "\t\tlabels_arr = np.repeat(np.array(labels_list),self._num_samples_per_class,axis=0)\n",
    "\t\t# print(labels_arr)\n",
    "\n",
    "\t\treturn labels_arr\n",
    "\n",
    "\tdef get_sample_data_train(self, indices_arr):\n",
    "\t\tsample = np.array(self._x_train[indices_arr,:,:,:])\n",
    "\t\t# print('Sample shape:{}'.format(sample.shape))\n",
    "\t\treturn sample\n",
    "\n",
    "\t# this function returns the next batch of samples and labels for training\n",
    "\tdef next_batch_train(self):\n",
    "\t\tindices_list = list()\n",
    "\t\t# num classes is the number of classes in each batch and we have to generate num_classes*num_samples_per_class samples\n",
    "\t\t# samples is different from instances as samples are the bags and instances are the images\n",
    "\t\tfor i in range(self._num_classes):\n",
    "\t\t\tclass_key = 'class_' + str(i)\n",
    "\t\t\t# print('class_key:{}'.format(class_key))\n",
    "\t\t\t\n",
    "\t\t\tfor j in range(self._num_samples_per_class):\n",
    "\t\t\t\tind = self._class_dict_train[class_key]['index']\n",
    "\n",
    "\t\t\t\t# here we are getting the tuple of digits for each class\t\n",
    "\t\t\t\ttemp_elements = self._class_dict_train[class_key]['tuples_arr'][ind,:]\n",
    "\n",
    "\t\t\t\tnum_elements = temp_elements.shape[0]\n",
    "\n",
    "\t\t\t\tnum_instances_per_element = self._num_instances // num_elements\n",
    "\t\t\t\tremainder_size = self._num_instances % num_elements\n",
    "\n",
    "\t\t\t\tnum_instances_arr = np.repeat(num_instances_per_element,num_elements)\n",
    "\t\t\t\tnum_instances_arr[:remainder_size] += 1\n",
    "\n",
    "\t\t\t\t# this part is used to generate the indices of the instances for each sample\n",
    "\t\t\t\tfor k in range(num_elements):\n",
    "\t\t\t\t\tdigit_key = 'digit' + str(temp_elements[k])\n",
    "\n",
    "\t\t\t\t\tnum_instances = num_instances_arr[k]\n",
    "\n",
    "\t\t\t\t\tindices_list += list(self._digit_dict[digit_key]['train_indices'][:num_instances])\n",
    "\n",
    "\t\t\t\t\tnp.random.shuffle(self._digit_dict[digit_key]['train_indices'])\n",
    "\n",
    "\n",
    "\t\t\t\tself._class_dict_train[class_key]['index'] += 1\n",
    "\n",
    "\t\t\t\t# if the index is greater than the number of tuples then we have to shuffle the tuples and reset the index\n",
    "\t\t\t\t# index is used to keep track of which tuple to use next\n",
    "\t\t\t\t# tuples are used to generate the bags\n",
    "\t\t\t\t# each tuple is a combination of digits\n",
    "\n",
    "\t\t\t\tif self._class_dict_train[class_key]['index'] >= self._class_dict_train[class_key]['num_tuples']:\n",
    "\t\t\t\t\tself._class_dict_train[class_key]['index'] = 0\n",
    "\t\t\t\t\tnp.random.shuffle(self._class_dict_train[class_key]['tuples_arr'])\n",
    "\n",
    "\t\t\n",
    "\t\tindices_arr = np.array(indices_list)\n",
    "\n",
    "\t\tsamples_arr = self.get_sample_data_train(indices_arr)\n",
    "\n",
    "\t\tsamples_arr = np.reshape(samples_arr, (-1,self._num_instances,samples_arr.shape[1],samples_arr.shape[2],samples_arr.shape[3]))\n",
    "\n",
    "\t\tsamples_data = np.transpose(samples_arr,(1,0,2,3,4))\n",
    "\n",
    "\t\tsamples = list(samples_data)\n",
    "\n",
    "\t\tlabels = self._labels\n",
    "\n",
    "\t\treturn samples, [labels,samples_arr]\n",
    "\n",
    "\tdef get_sample_data_val(self, indices_arr):\n",
    "\t\tsample = np.array(self._x_val[indices_arr,:,:,:])\n",
    "\n",
    "\t\treturn sample\n",
    "\n",
    "\tdef next_batch_val(self):\n",
    "\t\tindices_list = list()\n",
    "\t\tfor i in range(self._num_classes):\n",
    "\t\t\tclass_key = 'class_' + str(i)\n",
    "\t\t\t# print('class_key:{}'.format(class_key))\n",
    "\t\t\tfor j in range(self._num_samples_per_class):\n",
    "\t\t\t\tind = self._class_dict_val[class_key]['index']\n",
    "\t\t\t\t\n",
    "\t\t\t\ttemp_elements = self._class_dict_val[class_key]['tuples_arr'][ind,:]\n",
    "\n",
    "\t\t\t\tnum_elements = temp_elements.shape[0]\n",
    "\n",
    "\t\t\t\tnum_instances_per_element = self._num_instances // num_elements\n",
    "\t\t\t\tremainder_size = self._num_instances % num_elements\n",
    "\n",
    "\t\t\t\tnum_instances_arr = np.repeat(num_instances_per_element,num_elements)\n",
    "\t\t\t\tnum_instances_arr[:remainder_size] += 1\n",
    "\n",
    "\t\t\t\tfor k in range(num_elements):\n",
    "\t\t\t\t\tdigit_key = 'digit' + str(temp_elements[k])\n",
    "\n",
    "\t\t\t\t\tnum_instances = num_instances_arr[k]\n",
    "\n",
    "\t\t\t\t\tindices_list += list(self._digit_dict[digit_key]['val_indices'][:num_instances])\n",
    "\n",
    "\t\t\t\t\tnp.random.shuffle(self._digit_dict[digit_key]['val_indices'])\n",
    "\n",
    "\n",
    "\t\t\t\tself._class_dict_val[class_key]['index'] += 1\n",
    "\n",
    "\t\t\t\tif self._class_dict_val[class_key]['index'] >= self._class_dict_val[class_key]['num_tuples']:\n",
    "\t\t\t\t\tself._class_dict_val[class_key]['index'] = 0\n",
    "\t\t\t\t\tnp.random.shuffle(self._class_dict_val[class_key]['tuples_arr'])\n",
    "\n",
    "\t\t\n",
    "\t\tindices_arr = np.array(indices_list)\n",
    "\n",
    "\t\tsamples_arr = self.get_sample_data_val(indices_arr)\n",
    "\n",
    "\t\tsamples_arr = np.reshape(samples_arr, (-1,self._num_instances,samples_arr.shape[1],samples_arr.shape[2],samples_arr.shape[3]))\n",
    "\n",
    "\t\tsamples_data = np.transpose(samples_arr,(1,0,2,3,4))\n",
    "\n",
    "\t\tsamples = list(samples_data)\n",
    "\n",
    "\t\tlabels = self._labels\n",
    "\n",
    "\t\treturn samples, [labels,samples_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.layers import Flatten, concatenate, UpSampling2D, Reshape\n",
    "from keras.initializers import Constant, glorot_uniform\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.engine.topology import Input\n",
    "from keras.layers.convolutional import Conv2D, ZeroPadding3D\n",
    "from keras.layers.core import Activation, Dense, Dropout, Reshape, Flatten\n",
    "from keras.layers.merge import Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ProgbarLogger, BaseLogger\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Keras_Model(object):\n",
    "\tdef __init__(self, patch_size=28, num_instances=2, num_classes=2, learning_rate=1e-4, num_bins=None, num_features=10, batch_size=None):\n",
    "\t\tself._lr_rate=learning_rate\n",
    "\t\tself._num_features = num_features\n",
    "\n",
    "\t\tkernel_kwargs = {\n",
    "\t\t\t'kernel_initializer': glorot_uniform(),\n",
    "\t\t\t'kernel_regularizer': None\n",
    "\t\t}\n",
    "\n",
    "\t\tpatch_input = Input((28, 28, 1))\n",
    "\t\tx0 = Conv2D(16, (3, 3), padding='same', bias_initializer=Constant(value=0.1), **kernel_kwargs)(patch_input)\n",
    "\t\tx0 = self.wide_residual_blocks(x0, 2, 1, 16)\n",
    "\t\tx0 = self.wide_residual_blocks(x0, 4, 1, 16, True)\n",
    "\t\tx0 = self.wide_residual_blocks(x0, 8, 1, 16, True)\n",
    "\t\tx0 = Activation('relu')(x0)\n",
    "\t\tx0 = Flatten()(x0)\n",
    "\t\tprint('flatten shape:{}'.format(K.int_shape(x0)))\n",
    "\t\tpatch_output = Dense(self._num_features, activation='sigmoid', use_bias=False, name='fc_sigmoid', **kernel_kwargs)(x0)\n",
    "\t\tself._patch_model = Model(inputs=patch_input, outputs=patch_output)\n",
    "\t\t\n",
    "\t\tfeature_input = Input((self._num_features,))\n",
    "\t\tx1 = Dense(7*7*128, use_bias=True, bias_initializer=Constant(value=0.1), **kernel_kwargs)(feature_input)\n",
    "\t\tx1 = Reshape((7,7,128))(x1)\n",
    "\t\tx1 = self.wide_residual_blocks_reverse(x1, 8, 1, 16, True)\n",
    "\t\tx1 = self.wide_residual_blocks_reverse(x1, 4, 1, 16, True)\n",
    "\t\tx1 = self.wide_residual_blocks_reverse(x1, 2, 1, 16)\n",
    "\t\tx1 = Activation('relu')(x1)\n",
    "\t\treconstructed = Conv2D(1, (3, 3), padding='same', bias_initializer=Constant(value=0.1), **kernel_kwargs)(x1)\n",
    "\t\tprint('reconstructed shape:{}'.format(K.int_shape(reconstructed)))\n",
    "\t\tself._image_generation_model = Model(inputs=feature_input, outputs=reconstructed)\n",
    "\n",
    "\t\tae_output = self._image_generation_model(patch_output)\n",
    "\t\tself._autoencoder_model = Model(inputs=patch_input, outputs=ae_output)\n",
    "\n",
    "\t\tinput_list = list()\n",
    "\t\toutput_list = list()\n",
    "\t\tae_output_list = list()\n",
    "\t\tfor i in range(num_instances):\n",
    "\t\t\ttemp_input = Input(shape=(patch_size, patch_size, 1))\n",
    "\t\t\ttemp_output = self._patch_model(temp_input)\n",
    "\t\t\ttemp_output = Reshape((1,-1))(temp_output)\n",
    "\t\t\t# print('temp_output shape:{}'.format(K.int_shape(temp_output)))\n",
    "\n",
    "\t\t\ttemp_ae_output = self._autoencoder_model(temp_input)\n",
    "\t\t\ttemp_ae_output = Reshape((1,patch_size, patch_size, 1))(temp_ae_output)\n",
    "\n",
    "\t\t\tinput_list.append(temp_input)\n",
    "\t\t\toutput_list.append(temp_output)\n",
    "\t\t\tae_output_list.append(temp_ae_output)\n",
    "\n",
    "\n",
    "\t\tconcatenated = layers.concatenate(output_list,axis=1)\n",
    "\t\tprint('concatenated shape:{}'.format(K.int_shape(concatenated)))\n",
    "\n",
    "\t\tae_concatenated = layers.concatenate(ae_output_list,axis=1)\n",
    "\t\tprint('ae_concatenated shape:{}'.format(K.int_shape(ae_concatenated)))\n",
    "\n",
    "\t\ty = layers.Lambda(self.kde, arguments={'num_nodes':num_bins,'sigma':0.1,'batch_size':batch_size, 'num_features':self._num_features})(concatenated)\n",
    "\t\tprint('y shape:{}'.format(K.int_shape(y)))\n",
    "\n",
    "\t\ty1 = Dense(384, activation='relu', name='fc_relu1', **kernel_kwargs)(y)\n",
    "\t\ty1 = Dense(192, activation='relu', name='fc_relu2', **kernel_kwargs)(y1)\n",
    "\t\tout = Dense(num_classes, activation='softmax', name='fc_softmax', **kernel_kwargs)(y1)\n",
    "\n",
    "\n",
    "\t\tself._classification_model = Model(inputs=input_list, outputs=[out,ae_concatenated])\n",
    "\t\t\n",
    "\t\tself._ucc_model = Model(inputs=input_list, outputs=out)\n",
    "\t\n",
    "\t\toptimizer=Adam(lr=learning_rate)\n",
    "\t\tself._classification_model.compile(optimizer=optimizer, loss=['categorical_crossentropy','mse'], metrics=['accuracy'], loss_weights=[0.5, 0.5])\n",
    "\t\t\n",
    "\t\tself._distribution_model = Model(inputs=input_list, outputs=y)\n",
    "\n",
    "\t\tself._features_model = Model(inputs=input_list, outputs=concatenated)\n",
    "\n",
    "\n",
    "\t@property\n",
    "\tdef metrics_names(self):\n",
    "\t\treturn self._classification_model.metrics_names\n",
    "\t\n",
    "\t@property\n",
    "\tdef yaml_file(self):\n",
    "\t\treturn self._classification_model.to_yaml()\n",
    "\n",
    "\tdef kde(self, data, num_nodes=None, sigma=None, batch_size=None, num_features=None):\n",
    "\t\t# print('kde data shape:{}'.format(K.int_shape(data)))\n",
    "\t\t# print('num_nodes:{}'.format(num_nodes))\n",
    "\t\t# print('sigma:{}'.format(sigma))\n",
    "\n",
    "\t\tk_sample_points = K.constant( np.tile(np.linspace(0,1,num=num_nodes),[batch_size,K.int_shape(data)[1],1]) )\n",
    "\t\t# print('kde k_sample_points shape:{}'.format(K.int_shape(k_sample_points)))\n",
    "\n",
    "\t\tk_alfa = K.constant(1/np.sqrt(2*np.pi*np.square(sigma)))\n",
    "\t\tk_beta = K.constant(-1/(2*np.square(sigma)))\n",
    "\n",
    "\t\tout_list = list()\n",
    "\t\tfor i in range(num_features):\n",
    "\t\t\ttemp_data = K.reshape(data[:,:,i],(-1,K.int_shape(data)[1],1))\n",
    "\t\t\t# print('temp_data shape:{}'.format(K.int_shape(temp_data)))\n",
    "\n",
    "\t\t\tk_diff = k_sample_points - K.tile(temp_data,[1,1,num_nodes])\n",
    "\t\t\tk_diff_2 = K.square(k_diff)\n",
    "\t\t\t# print('k_diff_2 shape:{}'.format(K.int_shape(k_diff_2)))\n",
    "\n",
    "\t\t\tk_result = k_alfa * K.exp(k_beta*k_diff_2)\n",
    "\n",
    "\t\t\tk_out_unnormalized = K.sum(k_result,axis=1)\n",
    "\n",
    "\t\t\tk_norm_coeff = K.reshape(K.sum(k_out_unnormalized,axis=1),(-1,1))\n",
    "\n",
    "\t\t\tk_out = k_out_unnormalized / K.tile(k_norm_coeff, [1,K.int_shape(k_out_unnormalized)[1]])\n",
    "\t\t\t# print('k_out shape:{}'.format(K.int_shape(k_out)))\n",
    "\n",
    "\t\t\tout_list.append(k_out)\n",
    "\n",
    "\n",
    "\t\tconcat_out = K.concatenate(out_list,axis=-1)\n",
    "\t\t# print('concat_out shape:{}'.format(K.int_shape(concat_out)))\n",
    "\t\t\n",
    "\t\treturn concat_out\n",
    "\n",
    "\n",
    "\tdef residual_zero_padding_block(self, x0, filters, first_unit=False, down_sample=False):\n",
    "\t\tresidual_kwargs = {\n",
    "\t\t\t'kernel_size': (3, 3),\n",
    "\t\t\t'padding': 'same',\n",
    "\t\t\t'use_bias': True,\n",
    "\t\t\t'bias_initializer':Constant(value=0.1),\n",
    "\t\t\t'kernel_initializer': glorot_uniform(),\n",
    "\t\t\t'kernel_regularizer': None\n",
    "\t\t}\n",
    "\t\tskip_kwargs = {\n",
    "\t\t\t'kernel_size': (1, 1),\n",
    "\t\t\t'padding': 'valid',\n",
    "\t\t\t'use_bias': True,\n",
    "\t\t\t'kernel_initializer': glorot_uniform(),\n",
    "\t\t\t'kernel_regularizer': None\n",
    "\t\t}\n",
    "\n",
    "\t\tif first_unit:\n",
    "\t\t\tx0 = Activation('relu')(x0)\n",
    "\t\t\tif down_sample:\n",
    "\t\t\t\tresidual_kwargs['strides'] = (2, 2)\n",
    "\t\t\t\tskip_kwargs['strides'] = (2, 2)\n",
    "\t\t\tx1 = Conv2D(filters, **residual_kwargs)(x0)\n",
    "\t\t\tx1 = Activation('relu')(x1)\n",
    "\t\t\tresidual_kwargs['strides'] = (1, 1)\n",
    "\t\t\tx1 = Conv2D(filters, **residual_kwargs)(x1)\n",
    "\t\t\tx0_img_shape = x0.shape.as_list()[1:-1]\n",
    "\t\t\tx1_img_shape = x1.shape.as_list()[1:-1]\n",
    "\t\t\tprint('x0_img_shape:{}'.format(x0_img_shape))\n",
    "\t\t\tprint('x1_img_shape:{}'.format(x1_img_shape))\n",
    "\t\t\tprint('x0 shape:{}'.format(K.int_shape(x0)))\n",
    "\t\t\tprint('x1 shape:{}'.format(K.int_shape(x1)))\n",
    "\t\t\tx0_filters = x0.shape.as_list()[-1]\n",
    "\t\t\tx1_filters = x1.shape.as_list()[-1]\n",
    "\t\t\tif x0_img_shape != x1_img_shape:\n",
    "\t\t\t\tx0 = Conv2D(x0_filters, **skip_kwargs)(x0)\n",
    "\t\t\tif x0_filters != x1_filters:\n",
    "\t\t\t\ttarget_shape = (x1_img_shape[0], x1_img_shape[1], x0_filters, 1)\n",
    "\t\t\t\tx0 = Reshape(target_shape)(x0)\n",
    "\t\t\t\tzero_padding_size = x1_filters - x0_filters\n",
    "\t\t\t\tx0 = ZeroPadding3D(((0, 0), (0, 0), (0, zero_padding_size)))(x0)\n",
    "\t\t\t\ttarget_shape = (x1_img_shape[0], x1_img_shape[1], x1_filters)\n",
    "\t\t\t\tx0 = Reshape(target_shape)(x0)\n",
    "\t\telse:\n",
    "\t\t\tx1 = Activation('relu')(x0)\n",
    "\t\t\tx1 = Conv2D(filters, **residual_kwargs)(x1)\n",
    "\t\t\tx1 = Activation('relu')(x1)\n",
    "\t\t\tx1 = Conv2D(filters, **residual_kwargs)(x1)\n",
    "\t\tx0 = Add()([x0, x1])\n",
    "\t\treturn x0\n",
    "\n",
    "\n",
    "\tdef wide_residual_blocks(self, x0, filters, n, k, down_sample=False):\n",
    "\t\tfor i in range(n):\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tx0 = self.residual_zero_padding_block(x0, filters * k, True, down_sample)\n",
    "\t\t\telse:\n",
    "\t\t\t\tx0 = self.residual_zero_padding_block(x0, filters * k)\n",
    "\t\treturn x0\n",
    "\n",
    "\tdef wide_residual_blocks_reverse(self, x0, filters, n, k, up_sample=False):\n",
    "\t\tfor i in range(n):\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tx0 = self.residual_zero_padding_block_reverse(x0, filters * k, True, up_sample)\n",
    "\t\t\telse:\n",
    "\t\t\t\tx0 = self.residual_zero_padding_block_reverse(x0, filters * k)\n",
    "\t\treturn x0\n",
    "\n",
    "\tdef residual_zero_padding_block_reverse(self, x0, filters, first_unit=False, up_sample=False):\n",
    "\t\tresidual_kwargs = {\n",
    "\t\t\t'kernel_size': (3, 3),\n",
    "\t\t\t'padding': 'same',\n",
    "\t\t\t'use_bias': True,\n",
    "\t\t\t'bias_initializer':Constant(value=0.1),\n",
    "\t\t\t'kernel_initializer': glorot_uniform(),\n",
    "\t\t\t'kernel_regularizer': None\n",
    "\t\t}\n",
    "\t\tskip_kwargs = {\n",
    "\t\t\t'kernel_size': (1, 1),\n",
    "\t\t\t'padding': 'valid',\n",
    "\t\t\t'use_bias': True,\n",
    "\t\t\t'kernel_initializer': glorot_uniform(),\n",
    "\t\t\t'kernel_regularizer': None\n",
    "\t\t}\n",
    "\n",
    "\t\tif first_unit:\n",
    "\t\t\tx0 = Activation('relu')(x0)\n",
    "\t\t\tif up_sample:\n",
    "\t\t\t\tx0 = UpSampling2D((2, 2))(x0)\n",
    "\t\t\tx1 = Conv2D(filters, **residual_kwargs)(x0)\n",
    "\t\t\tx1 = Activation('relu')(x1)\n",
    "\t\t\tx1 = Conv2D(filters, **residual_kwargs)(x1)\n",
    "\t\t\tprint('x0 shape:{}'.format(K.int_shape(x0)))\n",
    "\t\t\tprint('x1 shape:{}'.format(K.int_shape(x1)))\n",
    "\t\t\tx0_filters = x0.shape.as_list()[-1]\n",
    "\t\t\tx1_filters = x1.shape.as_list()[-1]\n",
    "\t\t\tif x0_filters != x1_filters:\n",
    "\t\t\t\tx0 = Conv2D(filters, **skip_kwargs)(x0)\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tx1 = Activation('relu')(x0)\n",
    "\t\t\tx1 = Conv2D(filters, **residual_kwargs)(x1)\n",
    "\t\t\tx1 = Activation('relu')(x1)\n",
    "\t\t\tx1 = Conv2D(filters, **residual_kwargs)(x1)\n",
    "\t\tx0 = Add()([x0, x1])\n",
    "\t\t\n",
    "\t\treturn x0\n",
    "\n",
    "\tdef train_on_batch_data(self, batch_inputs=None, batch_outputs=None):\n",
    "\t\tstats = self._classification_model.train_on_batch(batch_inputs, batch_outputs)\n",
    "\n",
    "\t\treturn stats\n",
    "\n",
    "\tdef test_on_batch_data(self, batch_inputs=None, batch_outputs=None):\n",
    "\t\tstats = self._classification_model.test_on_batch(batch_inputs, batch_outputs)\n",
    "\n",
    "\t\treturn stats\n",
    "\n",
    "\tdef predict_on_batch_data(self, batch_inputs=None):\n",
    "\t\tpredicted_label = self._classification_model.predict_on_batch(batch_inputs)\n",
    "\n",
    "\t\treturn predicted_label\n",
    "\n",
    "\tdef predict_ucc_on_batch_data(self, batch_inputs=None):\n",
    "\t\tpredicted_label = self._ucc_model.predict_on_batch(batch_inputs)\n",
    "\n",
    "\t\treturn predicted_label\n",
    "\n",
    "\tdef predict_on_batch_data_ae(self, batch_inputs=None):\n",
    "\t\tpredicted_label = self._autoencoder_model.predict_on_batch(batch_inputs)\n",
    "\n",
    "\t\treturn predicted_label\n",
    "\n",
    "\tdef generate_image_from_feature(self, batch_inputs=None):\n",
    "\t\tpredicted_label = self._image_generation_model.predict_on_batch(batch_inputs)\n",
    "\n",
    "\t\treturn predicted_label\n",
    "\n",
    "\tdef predict_on_batch_data_distribution(self, batch_inputs=None):\n",
    "\t\tpredicted_dist = self._distribution_model.predict_on_batch(batch_inputs)\n",
    "\n",
    "\t\treturn predicted_dist\n",
    "\n",
    "\tdef predict_on_batch_data_features(self, batch_inputs=None):\n",
    "\t\tpredicted_features = self._features_model.predict_on_batch(batch_inputs)\n",
    "\n",
    "\t\treturn predicted_features\n",
    "\n",
    "\tdef predict_on_batch_data_patches(self, batch_inputs=None):\n",
    "\t\tpredicted_patches = self._patch_model.predict_on_batch(batch_inputs)\n",
    "\n",
    "\t\treturn predicted_patches\n",
    "\n",
    "\tdef save_model_weights(self, model_weight_save_path=None):\n",
    "\t\tself._classification_model.save_weights(model_weight_save_path)\n",
    "\t\tself._autoencoder_model.save_weights(model_weight_save_path[:-3]+'__ae.h5')\n",
    "\n",
    "\tdef load_saved_weights(self, weights_path=None):\n",
    "\t\tself._classification_model.load_weights(weights_path)\n",
    "\t\tself._autoencoder_model.load_weights(weights_path[:-3]+'__ae.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
